const std = @import("std");
const testing = std.testing;

const root = @import("root");
const Inst = root.aarch64_inst.Inst;
const abi_mod = root.abi;
const lower_mod = root.lower;
const compile_mod = root.compile;

/// CPU feature flags for aarch64.
/// Based on FEAT_* extensions in ARMv8 architecture.
pub const Features = packed struct {
    /// Has Large System Extensions (FEAT_LSE) - atomic instructions
    /// Provides atomic memory operations (LDADD, LDCLR, etc.)
    has_lse: bool = false,

    /// Has Pointer Authentication (FEAT_PAuth)
    /// Enables use of non-HINT PAC instructions
    has_pauth: bool = false,

    /// Has Branch Target Identification (FEAT_BTI)
    /// Control flow integrity via BTI landing pads
    has_bti: bool = false,

    /// Has half-precision floating point (FEAT_FP16)
    /// Native FP16 arithmetic operations
    has_fp16: bool = false,

    /// Has Scalable Vector Extension (SVE)
    /// Vector length-agnostic SIMD
    has_sve: bool = false,

    /// Has Scalable Matrix Extension (SME)
    /// Scalable matrix operations
    has_sme: bool = false,

    /// Has Advanced SIMD and FP support (NEON)
    /// Standard 128-bit SIMD - baseline for aarch64
    has_neon: bool = true,

    /// Has cryptographic extensions (FEAT_AES, FEAT_SHA*)
    /// AES, SHA1, SHA256, etc. instructions
    has_crypto: bool = false,

    /// Reserved for future features
    _reserved: u24 = 0,

    pub fn init() Features {
        return .{};
    }

    /// Detect native CPU features at runtime.
    /// Platform-specific feature detection.
    pub fn detectNative() Features {
        // On macOS ARM64, most features are available
        if (@import("builtin").target.os.tag == .macos) {
            return .{
                .has_neon = true,
                .has_crypto = true,
                .has_fp16 = true,
                .has_lse = true,
                // Conservative defaults for security features
                .has_pauth = false,
                .has_bti = false,
                .has_sve = false,
                .has_sme = false,
            };
        }
        return init();
    }

    /// Check if LSE atomics are preferred.
    pub fn preferLseAtomics(self: Features) bool {
        return self.has_lse;
    }

    /// Check if pointer auth is available for code generation.
    pub fn canUsePauth(self: Features) bool {
        return self.has_pauth;
    }
};

/// Tuning flags for code generation.
/// These control security features and optimization preferences.
pub const TuningFlags = struct {
    /// Sign return addresses for security (FEAT_PAuth)
    /// Uses HINT-space instructions (PACIASP/AUTIASP) by default
    sign_return_address: bool = false,

    /// Use B key instead of A key for pointer auth
    /// Some platform ABIs require this (e.g., some embedded targets)
    sign_return_address_with_bkey: bool = false,

    /// Sign all function returns, not just stack-using functions
    /// Applies return address signing to leaf functions too
    sign_return_address_all: bool = false,

    /// Prefer LSE atomics over LL/SC when available
    /// LSE provides better performance for atomic operations
    prefer_lse_atomics: bool = true,

    /// Use BTI landing pads (Branch Target Identification)
    /// Requires FEAT_BTI for control flow integrity
    use_bti: bool = false,

    pub fn init() TuningFlags {
        return .{};
    }

    /// Validate tuning flags against features.
    pub fn validate(self: TuningFlags, features: Features) !void {
        if (self.sign_return_address and !features.has_pauth) {
            return error.PauthNotAvailable;
        }
        if (self.use_bti and !features.has_bti) {
            return error.BtiNotAvailable;
        }
        if (self.prefer_lse_atomics and !features.has_lse) {
            // Just a preference, not an error
        }
    }
};

/// Encoding space constraints for AArch64 instruction formats.
pub const EncodingConstraints = struct {
    /// All instructions are 32-bit fixed-width.
    pub const instruction_size: u8 = 4;

    /// Maximum PC-relative branch range (±128MB for B/BL).
    pub const max_branch_offset: i28 = 134_217_727; // 2^27 - 1

    /// Maximum conditional branch range (±1MB for B.cond).
    pub const max_cond_branch_offset: i21 = 1_048_575; // 2^20 - 1

    /// Maximum load/store offset for immediate addressing (12-bit unsigned).
    pub const max_load_store_imm: u12 = 4095;

    /// Maximum arithmetic immediate (12-bit + optional 12-bit shift).
    pub const max_arith_imm: u24 = 0xFFF_000;

    /// Maximum shift amount for 64-bit operations.
    pub const max_shift_64: u6 = 63;

    /// Maximum shift amount for 32-bit operations.
    pub const max_shift_32: u6 = 31;
};

/// ISA capabilities - what operations are natively supported.
pub const Capabilities = struct {
    /// Native fused multiply-add (FMA) support via NEON.
    pub const has_native_fma: bool = true;

    /// Native rounding instructions (FRINT*).
    pub const has_native_round: bool = true;

    /// Vector width in bytes (NEON is always 128-bit).
    pub const vector_width_bytes: u8 = 16;

    /// Vector register count.
    pub const num_vector_regs: u8 = 32;

    /// Default argument extension behavior (zero-extend for AArch64).
    pub const default_arg_extension: enum { zero, sign } = .zero;

    /// Page size alignment (platform-dependent).
    pub fn pageAlignmentLog2(os: std.Target.Os.Tag) u8 {
        return switch (os) {
            // macOS/iOS use 16KB pages
            .macos, .ios, .tvos, .watchos => 14, // 2^14 = 16384
            // Linux and others typically use 64KB on ARM64
            else => 16, // 2^16 = 65536
        };
    }

    /// Function alignment in bytes (4 bytes, aligned to instruction boundary).
    pub const function_alignment: u8 = 4;
};

/// ARM64 ISA descriptor.
/// This integrates all aarch64 backend components into a unified interface.
pub const Aarch64ISA = struct {
    /// ISA name.
    pub const name = "aarch64";

    /// Machine instruction type.
    pub const MachInst = Inst;

    /// CPU features detected or configured.
    features: Features = Features.init(),

    /// Code generation tuning flags.
    tuning: TuningFlags = TuningFlags.init(),

    /// Target operating system (affects page alignment, ABI details).
    target_os: std.Target.Os.Tag = .freestanding,

    /// Initialize ISA descriptor with default settings.
    pub fn init() Aarch64ISA {
        return .{};
    }

    /// Initialize with native CPU features.
    pub fn initNative(os: std.Target.Os.Tag) Aarch64ISA {
        return .{
            .features = Features.detectNative(),
            .target_os = os,
        };
    }

    /// ABI specification for this ISA.
    pub fn abi(call_conv: abi_mod.CallConv) abi_mod.ABIMachineSpec(u64) {
        return switch (call_conv) {
            .aapcs64 => @import("abi.zig").aapcs64(),
            .system_v, .windows_fastcall => unreachable,
        };
    }

    /// Lowering backend for instruction selection.
    pub fn lower() lower_mod.LowerBackend(Inst) {
        return @import("lower.zig").Aarch64Lower.backend();
    }

    /// Register information.
    pub const registers = struct {
        /// Number of general-purpose registers (X0-X30).
        pub const num_gpr: u8 = 31;
        /// Number of vector registers (V0-V31).
        pub const num_vec: u8 = 32;
        /// Stack pointer register.
        pub const sp_reg = 31; // SP (X31)
        /// Frame pointer register.
        pub const fp_reg = 29; // X29
        /// Link register.
        pub const lr_reg: ?u8 = 30; // X30
    };

    /// Compile a function to machine code using this ISA.
    pub fn compileFunction(
        ctx: compile_mod.CompileCtx,
        func: *const lower_mod.Function,
    ) !compile_mod.CompiledCode {
        return compile_mod.compile(
            Inst,
            ctx,
            func,
            lower(),
        );
    }

    /// Check if branch target identification is enabled.
    pub fn isBranchProtectionEnabled(self: Aarch64ISA) bool {
        return self.tuning.use_bti and self.features.has_bti;
    }

    /// Get dynamic vector width in bytes.
    /// For standard NEON, this is always 16 bytes (128 bits).
    /// SVE would use runtime detection.
    pub fn dynamicVectorBytes(self: Aarch64ISA) u32 {
        _ = self;
        return Capabilities.vector_width_bytes;
    }

    /// Get page alignment for this target.
    pub fn pageAlignmentLog2(self: Aarch64ISA) u8 {
        return Capabilities.pageAlignmentLog2(self.target_os);
    }
};

test "Aarch64ISA basic properties" {
    try testing.expectEqualStrings("aarch64", Aarch64ISA.name);
    try testing.expectEqual(@as(u8, 31), Aarch64ISA.registers.num_gpr);
    try testing.expectEqual(@as(u8, 32), Aarch64ISA.registers.num_vec);
    try testing.expectEqual(@as(u8, 31), Aarch64ISA.registers.sp_reg);
    try testing.expectEqual(@as(u8, 29), Aarch64ISA.registers.fp_reg);
    try testing.expectEqual(@as(u8, 30), Aarch64ISA.registers.lr_reg.?);
}

test "Aarch64ISA ABI selection" {
    const aapcs = Aarch64ISA.abi(.aapcs64);

    // AAPCS64 has 8 int arg regs (X0-X7)
    try testing.expectEqual(@as(usize, 8), aapcs.int_arg_regs.len);

    // AAPCS64 has 8 float arg regs (V0-V7)
    try testing.expectEqual(@as(usize, 8), aapcs.float_arg_regs.len);
}

test "Aarch64ISA lowering backend" {
    const backend = Aarch64ISA.lower();

    // Should have function pointers
    try testing.expect(@intFromPtr(backend.lowerInstFn) != 0);
    try testing.expect(@intFromPtr(backend.lowerBranchFn) != 0);
}

test "Aarch64ISA compile function" {
    var func = lower_mod.Function.init(testing.allocator);
    defer func.deinit();

    const ctx = compile_mod.CompileCtx.init(testing.allocator, "aarch64");

    var code = try Aarch64ISA.compileFunction(ctx, &func);
    defer code.deinit();

    // Empty function produces minimal code
    try testing.expect(code.code.len == 0);
}

test "CPU Features initialization" {
    const features = Features.init();
    try testing.expect(!features.has_lse);
    try testing.expect(!features.has_pauth);
    try testing.expect(!features.has_sve);
    try testing.expect(!features.has_sme);
    try testing.expect(features.has_neon);
    try testing.expect(!features.has_crypto);
}

test "CPU Features native detection" {
    const features = Features.detectNative();
    try testing.expect(features.has_neon);
    // macOS ARM64 should have these
    if (@import("builtin").target.os.tag == .macos) {
        try testing.expect(features.has_lse);
        try testing.expect(features.has_fp16);
        try testing.expect(features.has_crypto);
    }
}

test "TuningFlags initialization" {
    const tuning = TuningFlags.init();
    try testing.expect(!tuning.sign_return_address);
    try testing.expect(tuning.prefer_lse_atomics);
    try testing.expect(!tuning.use_bti);
}

test "Aarch64ISA with features" {
    const isa = Aarch64ISA{
        .features = Features{
            .has_lse = true,
            .has_neon = true,
        },
    };
    try testing.expect(isa.features.has_lse);
    try testing.expect(isa.features.has_neon);
    try testing.expect(!isa.features.has_sve);
}
